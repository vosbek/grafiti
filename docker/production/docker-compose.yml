version: '3.8'

services:
  # Backend API Service (Production)
  backend:
    image: codeanalysis-mvp:latest
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    ports:
      - "8000:8000"
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD_FILE=/run/secrets/neo4j_password
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=codeanalysis
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - REDIS_URL=redis://redis:6379
      - SECRET_KEY_FILE=/run/secrets/app_secret_key
      - DEVICE=cuda
      - EMBEDDING_BATCH_SIZE=32
      - MAX_CONCURRENT_CLONES=8
      - ENABLE_METRICS=true
    volumes:
      - repositories_data:/app/repositories
      - embeddings_data:/app/embeddings
      - analysis_results:/app/analysis-results
    secrets:
      - neo4j_password
      - postgres_password
      - app_secret_key
    depends_on:
      - neo4j
      - postgres
      - redis
    networks:
      - codeanalysis-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery Workers (Production)
  worker:
    image: codeanalysis-mvp:latest
    command: celery -A backend.app.main.celery worker --loglevel=info --concurrency=4 --max-tasks-per-child=1000
    deploy:
      replicas: 5
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD_FILE=/run/secrets/neo4j_password
      - POSTGRES_HOST=postgres
      - POSTGRES_USER=codeanalysis
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/1
      - CELERY_RESULT_BACKEND=redis://redis:6379/2
      - DEVICE=cuda
    volumes:
      - repositories_data:/app/repositories
      - embeddings_data:/app/embeddings
    secrets:
      - neo4j_password
      - postgres_password
    depends_on:
      - redis
      - postgres
      - neo4j
    networks:
      - codeanalysis-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Celery Beat Scheduler (Production)
  scheduler:
    image: codeanalysis-mvp:latest
    command: celery -A backend.app.main.celery beat --loglevel=info --schedule=/app/celerybeat-schedule
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      - ENVIRONMENT=production
      - REDIS_URL=redis://redis:6379
      - CELERY_BROKER_URL=redis://redis:6379/1
    volumes:
      - celery_schedule:/app
    depends_on:
      - redis
    networks:
      - codeanalysis-network

  # Neo4j Graph Database (Production)
  neo4j:
    image: neo4j:5.15-enterprise
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '2'
          memory: 4G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      - NEO4J_AUTH=neo4j/production-password
      - NEO4J_ACCEPT_LICENSE_AGREEMENT=yes
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_memory_heap_initial_size=4G
      - NEO4J_dbms_memory_heap_max_size=6G
      - NEO4J_dbms_memory_pagecache_size=2G
      - NEO4J_dbms_jvm_additional=-XX:+ExitOnOutOfMemoryError
      - NEO4J_dbms_backup_enabled=true
      - NEO4J_dbms_backup_listen_address=0.0.0.0:6362
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
      - neo4j_import:/var/lib/neo4j/import
      - neo4j_plugins:/plugins
      - neo4j_backups:/backups
    ports:
      - "7687:7687"
    networks:
      - codeanalysis-network
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "production-password", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # PostgreSQL Database (Production)
  postgres:
    image: postgres:15
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      - POSTGRES_DB=codeanalysis
      - POSTGRES_USER=codeanalysis
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
      - POSTGRES_MAX_CONNECTIONS=200
      - POSTGRES_SHARED_BUFFERS=256MB
      - POSTGRES_EFFECTIVE_CACHE_SIZE=1GB
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - postgres_backups:/backups
      - ./production-init-scripts:/docker-entrypoint-initdb.d
    secrets:
      - postgres_password
    networks:
      - codeanalysis-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U codeanalysis -d codeanalysis"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

  # Redis Cache and Message Broker (Production)
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes --maxmemory 4gb --maxmemory-policy allkeys-lru --save 60 1000
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '2'
          memory: 5G
        reservations:
          cpus: '0.5'
          memory: 1G
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    volumes:
      - redis_data:/data
    networks:
      - codeanalysis-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Frontend React Application (Production)
  frontend:
    image: codeanalysis-frontend:latest
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    environment:
      - REACT_APP_API_URL=https://api.yourdomain.com
      - REACT_APP_ENVIRONMENT=production
    networks:
      - codeanalysis-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Nginx Load Balancer (Production)
  nginx:
    image: nginx:alpine
    deploy:
      replicas: 2
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.1'
          memory: 128M
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx-production.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - backend
      - frontend
    networks:
      - codeanalysis-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Prometheus Monitoring
  prometheus:
    image: prom/prometheus:latest
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '1'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    volumes:
      - ./prometheus-production.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=90d'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    ports:
      - "9090:9090"
    networks:
      - codeanalysis-network
      - monitoring-network

  # Grafana Visualization
  grafana:
    image: grafana/grafana:latest
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 256M
    environment:
      - GF_SECURITY_ADMIN_PASSWORD_FILE=/run/secrets/grafana_admin_password
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel,grafana-worldmap-panel
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/production-dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/production-datasources:/etc/grafana/provisioning/datasources
    secrets:
      - grafana_admin_password
    depends_on:
      - prometheus
    ports:
      - "3001:3000"
    networks:
      - monitoring-network

  # Backup Service
  backup:
    image: codeanalysis-backup:latest
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.1'
          memory: 256M
      restart_policy:
        condition: on-failure
        delay: 60s
        max_attempts: 3
    environment:
      - BACKUP_SCHEDULE=0 2 * * *  # Daily at 2 AM
      - S3_BUCKET=${BACKUP_S3_BUCKET}
      - AWS_ACCESS_KEY_ID_FILE=/run/secrets/aws_access_key_id
      - AWS_SECRET_ACCESS_KEY_FILE=/run/secrets/aws_secret_access_key
    volumes:
      - neo4j_data:/data/neo4j:ro
      - postgres_backups:/data/postgres:ro
      - repositories_data:/data/repositories:ro
      - /var/run/docker.sock:/var/run/docker.sock
    secrets:
      - aws_access_key_id
      - aws_secret_access_key
    networks:
      - codeanalysis-network

secrets:
  neo4j_password:
    external: true
  postgres_password:
    external: true
  app_secret_key:
    external: true
  grafana_admin_password:
    external: true
  aws_access_key_id:
    external: true
  aws_secret_access_key:
    external: true

volumes:
  neo4j_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/neo4j
  neo4j_logs:
    driver: local
  neo4j_import:
    driver: local
  neo4j_plugins:
    driver: local
  neo4j_backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /backups/neo4j
  postgres_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/postgres
  postgres_backups:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /backups/postgres
  redis_data:
    driver: local
  repositories_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/repositories
  embeddings_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/embeddings
  analysis_results:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: /data/analysis-results
  celery_schedule:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  nginx_logs:
    driver: local

networks:
  codeanalysis-network:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.0.1.0/24
  monitoring-network:
    driver: overlay
    attachable: true
    ipam:
      config:
        - subnet: 10.0.2.0/24